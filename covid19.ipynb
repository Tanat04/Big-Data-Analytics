{"cells": [{"cell_type": "code", "execution_count": 59, "id": "5cf1f422-9a6d-40af-9262-e62e7460d206", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/09/09 10:30:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}], "source": "from pyspark.sql import SparkSession\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Initialize Spark session\nspark = SparkSession.builder.appName(\"COVID-19 Linear Regression\").getOrCreate()"}, {"cell_type": "code", "execution_count": 89, "id": "5754fe6b-3f1a-47d0-9378-01d98e209432", "metadata": {}, "outputs": [], "source": "# Load COVID-19 data from Cloud Storage\ncovid_data = spark.read.csv(\"gs://6410381/covidData/covid19.csv\", header=True, inferSchema=True)"}, {"cell_type": "code", "execution_count": 90, "id": "b39a2cb8-27fc-4fb6-8aec-da5d29b7a5da", "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[date: timestamp, new_confirmed: int]"}, "execution_count": 90, "metadata": {}, "output_type": "execute_result"}], "source": "covid_data"}, {"cell_type": "code", "execution_count": 91, "id": "5cc44147-06bb-42bc-927e-152fde56333c", "metadata": {}, "outputs": [{"data": {"text/plain": "[Row(date=datetime.datetime(2020, 1, 1, 0, 0), new_confirmed=0),\n Row(date=datetime.datetime(2020, 1, 2, 0, 0), new_confirmed=0),\n Row(date=datetime.datetime(2020, 1, 3, 0, 0), new_confirmed=0),\n Row(date=datetime.datetime(2020, 1, 4, 0, 0), new_confirmed=0),\n Row(date=datetime.datetime(2020, 1, 5, 0, 0), new_confirmed=0)]"}, "execution_count": 91, "metadata": {}, "output_type": "execute_result"}], "source": "covid_data.take(5)"}, {"cell_type": "code", "execution_count": 92, "id": "afcc1e16-1cb9-4218-9f01-faeabc52d9fd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- date: timestamp (nullable = true)\n |-- new_confirmed: integer (nullable = true)\n\n"}], "source": "covid_data.printSchema()"}, {"cell_type": "code", "execution_count": 93, "id": "aa6ae169-4c5c-4e8a-89df-8885181b48da", "metadata": {}, "outputs": [{"data": {"text/plain": "991"}, "execution_count": 93, "metadata": {}, "output_type": "execute_result"}], "source": "covid_data.count()"}, {"cell_type": "code", "execution_count": 94, "id": "9875a74c-fde2-4699-acfc-2ce5d26ffaec", "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[date: timestamp, new_confirmed: int]"}, "execution_count": 94, "metadata": {}, "output_type": "execute_result"}], "source": "covid_data.dropna()"}, {"cell_type": "code", "execution_count": 95, "id": "4eebe00a-0c70-4ff6-ab61-f1701a298b0b", "metadata": {}, "outputs": [{"data": {"text/plain": "991"}, "execution_count": 95, "metadata": {}, "output_type": "execute_result"}], "source": "covid_data.count()"}, {"cell_type": "code", "execution_count": 96, "id": "1beb0c3e-6155-43be-a574-ceab5a55c6e7", "metadata": {}, "outputs": [], "source": "features_df = covid_data.select(['date', 'new_confirmed']).na.drop()"}, {"cell_type": "code", "execution_count": 97, "id": "d70776c4-eeaf-4a8f-ae8b-199ef9cf9373", "metadata": {}, "outputs": [], "source": "training_df, test_df = features_df.randomSplit([0.8, 0.2], seed=12)\n"}, {"cell_type": "code", "execution_count": 98, "id": "e149c939-6a04-4278-a416-1ed2f402f08e", "metadata": {}, "outputs": [], "source": "featureAssembler = VectorAssembler(inputCols=['new_confirmed'], outputCol='features')\n"}, {"cell_type": "code", "execution_count": 99, "id": "9680175b-c6f9-4961-bf1c-adfdf8d2f4cf", "metadata": {}, "outputs": [], "source": "lr = LinearRegression(labelCol='new_confirmed', featuresCol='features')\n"}, {"cell_type": "code", "execution_count": 100, "id": "4aedcd9c-fd1e-4c6d-a89d-a07ca477ac5a", "metadata": {}, "outputs": [], "source": "from pyspark.ml import Pipeline\n\npipeline_lr = Pipeline(stages=[featureAssembler, lr])\n"}, {"cell_type": "code", "execution_count": 101, "id": "349d99d6-90df-4042-a0e4-a84909e3dcff", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/09/09 10:59:51 WARN Instrumentation: [822038ed] regParam is zero, which might cause numerical instability and overfitting.\n"}], "source": "lrModel = pipeline_lr.fit(training_df)\n"}, {"cell_type": "code", "execution_count": 102, "id": "01be75f8-493c-4ef0-a9bd-c52193617c48", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------+------------------+\n|new_confirmed|        prediction|\n+-------------+------------------+\n|            0|               0.0|\n|            0|               0.0|\n|            0|               0.0|\n|            0|               0.0|\n|            0|               0.0|\n|            1|0.9999999999999998|\n|            1|0.9999999999999998|\n|            0|               0.0|\n|            0|               0.0|\n|            0|               0.0|\n|            0|               0.0|\n|            0|               0.0|\n|            1|0.9999999999999998|\n|            6| 5.999999999999998|\n|           12|11.999999999999996|\n|           75| 74.99999999999999|\n|          152|151.99999999999997|\n|          181|180.99999999999997|\n|          116|115.99999999999997|\n|          157|156.99999999999997|\n+-------------+------------------+\nonly showing top 20 rows\n\n"}], "source": "predictions = lrModel.transform(test_df)\npredictions.select(['new_confirmed', 'prediction']).show()\n"}, {"cell_type": "code", "execution_count": null, "id": "3e2014e1-1ec5-471f-b9b0-bd8956dd3327", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}